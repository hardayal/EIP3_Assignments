{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(32, (3, 3))`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(64, (3, 3))`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (1, 1))`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `SeparableConv2D` call to the Keras 2 API: `SeparableConv2D(128, (3, 3))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 24, 24, 32)        1344      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_2 (Separabl (None, 10, 10, 64)        2400      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 10, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 32)        2080      \n",
      "_________________________________________________________________\n",
      "separable_conv2d_3 (Separabl (None, 8, 8, 128)         4512      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 10)          1290      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4, 4, 10)          40        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1, 1, 10)          1610      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 14,620\n",
      "Trainable params: 14,088\n",
      "Non-trainable params: 532\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "235/234 [==============================] - 25s 108ms/step - loss: 0.7567 - acc: 0.7840 - val_loss: 0.1305 - val_acc: 0.9703\n",
      "Epoch 2/30\n",
      "235/234 [==============================] - 21s 90ms/step - loss: 0.1943 - acc: 0.9448 - val_loss: 0.0781 - val_acc: 0.9763\n",
      "Epoch 3/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.1273 - acc: 0.9638 - val_loss: 0.0846 - val_acc: 0.9734\n",
      "Epoch 4/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.1026 - acc: 0.9691 - val_loss: 0.0684 - val_acc: 0.9782\n",
      "Epoch 5/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0843 - acc: 0.9744 - val_loss: 0.0392 - val_acc: 0.9891\n",
      "Epoch 6/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0759 - acc: 0.9767 - val_loss: 0.0571 - val_acc: 0.9836\n",
      "Epoch 7/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0671 - acc: 0.9798 - val_loss: 0.0524 - val_acc: 0.9845\n",
      "Epoch 8/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0657 - acc: 0.9798 - val_loss: 0.0306 - val_acc: 0.9901\n",
      "Epoch 9/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0598 - acc: 0.9818 - val_loss: 0.0358 - val_acc: 0.9893\n",
      "Epoch 10/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0565 - acc: 0.9829 - val_loss: 0.0760 - val_acc: 0.9765\n",
      "Epoch 11/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0549 - acc: 0.9828 - val_loss: 0.0371 - val_acc: 0.9877\n",
      "Epoch 12/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0510 - acc: 0.9841 - val_loss: 0.0603 - val_acc: 0.9822\n",
      "Epoch 13/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0495 - acc: 0.9851 - val_loss: 0.0302 - val_acc: 0.9911\n",
      "Epoch 14/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0461 - acc: 0.9857 - val_loss: 0.0357 - val_acc: 0.9885\n",
      "Epoch 15/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0534 - val_acc: 0.9826\n",
      "Epoch 16/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0444 - acc: 0.9861 - val_loss: 0.0237 - val_acc: 0.9918\n",
      "Epoch 17/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0443 - acc: 0.9863 - val_loss: 0.0273 - val_acc: 0.9916\n",
      "Epoch 18/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0413 - acc: 0.9873 - val_loss: 0.0402 - val_acc: 0.9868\n",
      "Epoch 19/30\n",
      "235/234 [==============================] - 21s 91ms/step - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0268 - val_acc: 0.9912\n",
      "Epoch 20/30\n",
      "235/234 [==============================] - 22s 92ms/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0265 - val_acc: 0.9926\n",
      "Epoch 00019: early stopping THR\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd63bafaa58>"
      ]
     },
     "execution_count": 1,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "num_classes = 10\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_height, img_width = x_train.shape[1],x_train.shape[2]\n",
    "\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train/= 255\n",
    "x_test/= 255\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Conv2D, SeparableConv2D\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(SeparableConv2D(32, 3, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(SeparableConv2D(64, 3, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, 1, 1))\n",
    "model.add(SeparableConv2D(128, 3, 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(10, 1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Convolution2D(10, 4))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "class EarlyStoppingByAccuracy(Callback):\n",
    "    def __init__(self, monitor='val_acc', mode='max', value=0.98, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "        \n",
    "        if current >= self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStoppingByAccuracy(monitor='val_acc', value=0.992, verbose=1),\n",
    "    ModelCheckpoint(filepath='/tmp/weights.hdf5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "]          \n",
    "\n",
    "\n",
    "\n",
    "image_gen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.5,\n",
    "        zoom_range=(0.9, 1.1),\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='constant',\n",
    "        cval=0)\n",
    "\n",
    "\n",
    "image_gen.fit(x_train, augment=True)\n",
    "\n",
    "\n",
    "model.fit_generator(image_gen.flow(x_train, y_train, batch_size=256),\n",
    "          epochs=30,\n",
    "          steps_per_epoch=len(x_train)/(256),\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HARDAYAL_SINGH_BATCH_5_ASSIGNMENT_3A.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}